jupyterhub:
  #debug: 
  #  enabled: true
  auth:
    type: dummy
    dummy:
      password: 
  
  scheduling:
    userScheduler:
      enabled: true
    userPods:
      nodeAffinity:
        matchNodePurpose: require
    podPriority:
      enabled: true
      globalDefault: false
      defaultPriority: 0
      userPlaceholderPriority: -10
    corePods:
      nodeAffinity:
        matchNodePurpose: require
    userPlaceholder:
      enabled: true
      replicas: 1

  cull:
    enabled: true
    timeout: 3600    # cull inactive servers after this long
    every: 600       # how often to check 
    maxAge: 28800        # cull servers this old, even if active (0 disables)

  proxy:
    # this should get replaced when deployed with scripts/deploy_from_settings.sh
    secretToken: <%= $(openssl rand -hex 32) %>
    service: 
      type: ClusterIP
    https:
      enabled: true
      type: offload

  singleuser:
    # if nodes are labeled with their cost in cents-per-hour, this should help
    # schedule pods on the cheapest node they can fit on (notwithstanding influences by the custom scheduler and various requirements)
    extraNodeAffinity:
      preferred:
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "10"
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "20"
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "30"
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "40"
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "50"
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "60"
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "70"
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "80"
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "90"
      - weight: 100
        preference: 
          matchExpressions:
          - key: cents-per-hour
            operator: Lt
            values:
            - "100"
      # looks like these should be set null to delete the key (including those defaulted in the jupyterhub chart) for the c.Spawner limits below to be used
    memory:
      limit: 1.0G
      guarantee: 0.5G
    cpu:
      limit: 1.0
      guarantee: 0.1
    image:
      name: oneilsh/ktesting-datascience-notebook
      tag: "v1.1.6"
    defaultUrl: "/lab/tree/{username}"
    cmd: ["start-singleuser.sh", "--allow-root"]  # don't think I need this? 
    storage:
      type: none
      extraVolumes:
        - name: data-volume
          configMap:
            name: data-configmap
        - name: start-volume
          configMap:
            name: start-configmap
            defaultMode: 0554
      extraVolumeMounts:
        - name: start-volume
          mountPath: /usr/local/bin/start.sh
          subPath: start.sh
        - name: data-volume
          mountPath: /usr/local/bin/data

    extraEnv:
      NFS_SVC_HOME: <%= $DRIVE_RELEASE_NAME %>
    uid: 0
    fsGid: 0
    startTimeout: 1200
    profileQuota:
      checkEvery: 600  # default 600
      quotaDbFilename: "/srv/jupyterhub/profile_quotas.sqlite" # default "/srv/jupyterhub/profile_quotas.sqlite"

  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: "nginx"
      nginx.org/mergeable-ingress-type: "minion"
      nginx.org/websocket-services: "proxy-public"
    hosts:
      - <%= $(index clusterHostname "") %>
    tls:
      - hosts:
        - <%= $(index clusterHostname "") %>
  
  hub:
    baseUrl: <%= "/$RELEASE_NAME/" %>
    db:
      type: "sqlite-pvc"
      upgrade: false 
    image:
      name: oneilsh/jupyterlab-k8s-hub
      tag: "v1.4.3" 
    uid: 0
    fsGid: 0
    extraVolumes:
      - name: data-volume
        configMap:
          name: data-configmap
      - name: start-hub-volume
        configMap:
          name: start-hub-configmap
          defaultMode: 0554
    extraVolumeMounts:
      - name: data-volume
        mountPath: /usr/local/bin/data
      - name: start-hub-volume
        mountPath: /usr/local/bin/start-hub.sh
        subPath: start-hub.sh
    extraEnv:
      AUTH_TYPE: <%= $(index authType "lti") %>
      LTI_ID_KEYS: '["custom_canvas_user_login_id", "lis_person_contact_email_primary", "custom_canvas_user_login_id"]'
      LTI_ID_REGEXES: '["(^[^@]+)@oregonstate.edu$", "(^[^@]+@[^@]+$)", "(^[0-9a-f]{6,6})[0-9a-f]*$"]'
      LTI_ADMIN_ROLES: '["Instructor", "TeachingAssistant", "ContentDeveloper"]'
      LTI_CLIENT_KEY: <%= $LTI_CLIENT_KEY %>
      LTI_CLIENT_SECRET: <%= $LTI_CLIENT_SECRET %>
      # TODO:
      NFS_SVC_HOME: <%= $DRIVE_RELEASE_NAME %>
      # e.g. oneils,keistc
      # but only used if not using lti AUTH_TYPE
      ADMIN_USERS: <%= $(index adminUsers "") %> 

    extraConfig:
      concurrentSpawn:
        c.JupyterHub.concurrent_spawn_limit = 400
      templatePath:
        c.JupyterHub.template_paths = ['/nfs_home/.hub_local/announcement_templates']
      basedir: |
        c.KubeSpawner.notebook_dir = "/home"

      nfspriv: |
        from kubernetes import client
        def modify_pod_hook(spawner, pod):
            pod.spec.containers[0].security_context = client.V1SecurityContext(
                privileged=True,
                capabilities=client.V1Capabilities(
                    add=['SYS_ADMIN']
                )
            )
            return pod
        c.KubeSpawner.modify_pod_hook = modify_pod_hook

      profiles: |
        profile_list = get_config("singleuser.profileList", None)

        if profile_list:
            from jhprofilequota import profile_db
            
            quota_db_filename = get_config('singleuser.profileQuota.quotaDbFilename', '/srv/jupyterhub/profile_quotas.sqlite')
            profile_db.create_db(quota_db_filename) 
       
            checker_cmd = ['python3','-m', 'jhprofilequota']
            base_url = c.JupyterHub.get('base_url', '/')
            checker_cmd.append( '--url=http://127.0.0.1:8081' + url_path_join(base_url, 'hub/api'))
    
            checker_cmd.append('--quota_db_filename=%s' % quota_db_filename)
        
            check_every = get_config('singleuser.profileQuota.checkEvery', 600)
            checker_cmd.append('--check_every=%s' % check_every)

            profiles_json = json.dumps(get_config('singleuser.profileList', "[]"))
            # this feels awkward... but I don't want to make the profiles 'state' for the service if I can help it
            checker_cmd.append("--profiles_json=" + profiles_json)
        
            c.JupyterHub.services.append({
              'name': 'quota_checker',
              'admin': True,
              'command': checker_cmd
            })
    
    
    
    
    
            c.KubeSpawner.profile_form_template = """ 
            <script>
            // JupyterHub 0.8 applied form-control indisciminately to all form elements.
            // Can be removed once we stop supporting JupyterHub 0.8
            $(document).ready(function() {
                $('#kubespawner-profiles-list input[type="radio"]').removeClass('form-control');
            });
            </script>
            <style>
            /* The profile description should not be bold, even though it is inside the <label> tag */
            #kubespawner-profiles-list label p {
                font-weight: normal;
            }
    
            .input-group {
              margin-bottom: 10px;
              padding: 12px 12px;
             }
    
            .tooltip {
              position: relative;
              display: inline-block;
              border-bottom: 1px dotted black;  /* If you want dots under the hoverable text */
              font-size: 14px;
              opacity: 1;
            
            }
            
            .tooltip .tooltiptext {
              visibility: hidden;
              border-radius: 6px;
             
              position: absolute;
              z-index: 1;
            }
            
            .tooltip:hover .tooltiptext {
              visibility: visible;
            }
            
            
            .tooltip .tooltiptext {
              top: -5px;
              right: 105%;
              width: 400px;
            }
            </style>
            <div class='form-group' id='kubespawner-profiles-list'>
            {% for profile in profile_list %}
            <label for='profile-item-{{ profile.slug }}' class='form-control input-group'>
                <div class='col-md-1'>
                    <input type='radio' name='profile' id='profile-item-{{ profile.slug }}' value='{{ profile.slug }}' {% if profile.default %}checked{% endif %} {% if profile.quotaDisplayDisabled %}disabled{% endif %}/>
                </div>
                <div class="col-md-11">
                    <strong>{{ profile.display_name }}</strong> 
                    {% if profile.description %}
                        <p style="margin-top: 15px">{{ profile.description }}</p>
                    {% endif %}
                    {% if profile.hasQuota %}
                    <div style="font-weight: normal; position: absolute; top: 0px; right: 10px; ">
                        <div class="tooltip">(Quota Balance: {{ profile.quotaDisplayBalanceHours }} Hours) 
                            <div class="alert alert-info tooltiptext" role="alert">
                              <h4 class="alert-heading">Quota Details</h4>
                              <p>This profile is associated with a time-based quota. You can only start a server with this profile if your balance is <b>{{ profile.quotaDisplayMinToStartHours }}</b> hours or above, and running a server with this profile will drain your balance. </p>
                              <p style="margin-top: 10px;">Don't worry: your server won't be stopped if your balance goes negative during use (though inactivity timeouts and maximum runtime limits still apply).</p>
                              <p style="margin-top: 10px;">Your quota for this profile is replenished at a rate of <b>{{ profile.quotaDisplayRateHoursPerDay }}</b> hours/day, up to a maximum balance of <b>{{ profile.quotaDisplayMaxBalanceHours }}</b> hours.</p>
                            </div>
                        </div>
                    </div>
                    {% endif %}    
                </div>
            </label>
            {% endfor %}
            </div>
            """
    
            from kubespawner import KubeSpawner
            class KubeSpawnerWithProfileInfo(KubeSpawner):
                def get_state(self):
                    state = super().get_state()
                    state['profile_slug'] = self.user_options["profile"]  # from the form element name? apparently not, changing the ratio name="profile-slug" and here "profile-slug" doesn't work
                    return state
    
            c.JupyterHub.spawner_class = KubeSpawnerWithProfileInfo
    
            def profiles_gen(spawner):
                profiles_list = get_config("singleuser.profileList", [])
    
                conn = profile_db.get_connection(quota_db_filename)
    
                profile_db.update_user_tokens(conn, profiles_list, spawner.user.name, spawner.user.admin)
                updated_profiles = profile_db.get_profiles_by_balance(conn, profiles_list, spawner.user.name, spawner.user.admin)
    
                profile_db.close_connection(conn)
                return updated_profiles 
    
            c.KubeSpawner.profile_list = profiles_gen
    
      authsetting: |
        import os
        import json

        env_auth_type = os.environ["AUTH_TYPE"]

        if env_auth_type == "native":
          from nativeauthenticator import NativeAuthenticator
          from tornado import gen

          class NativeExtraAuthenticator(NativeAuthenticator):
            @gen.coroutine
            def pre_spawn_start(self, user, spawner):
              # for use by scripts in start-notebook.d
              # NB_USER is the username logged in with
              # ADMIN_USER is "True" if they're an admin, "False" otherwise
              spawner.environment['NB_USER'] = user.name
              spawner.environment['ADMIN_USER'] = str(user.admin)
              # below for debugging
              #spawner.environment['NB_UID'] = "1000"
              #spawner.environment['GRANT_SUDO'] = "yes"
       
          c.JupyterHub.authenticator_class = NativeExtraAuthenticator
          # location in docker image
          c.JupyterHub.template_paths = ["/home/jovyan/nativeauthenticator/nativeauthenticator/templates/"]       

        elif env_auth_type == "lti":
          from ltiauthenticator import LTIAuthenticator
          from tornado import gen

          class LTIExtraAuthenticator(LTIAuthenticator):
            @gen.coroutine
            def pre_spawn_start(self, user, spawner):
              # for use by scripts in start-notebook.d
              # NB_USER is the username logged in with
              # ADMIN_USER is "True" if they're an admin, "False" otherwise
              spawner.environment['NB_USER'] = user.name
              spawner.environment['ADMIN_USER'] = str(user.admin)
              # below for debugging
              #spawner.environment['NB_UID'] = "1000"
              #spawner.environment['GRANT_SUDO'] = "yes"
       
          c.JupyterHub.authenticator_class = LTIExtraAuthenticator
          c.LTIExtraAuthenticator.consumers = {
            os.environ['LTI_CLIENT_KEY']: os.environ['LTI_CLIENT_SECRET']
          } 

          # take JSON-encoded environment vars 
          c.LTIExtraAuthenticator.user_id_keys = json.loads(os.environ["LTI_ID_KEYS"]) #eg '["custom_canvas_user_login_id", "lis_person_contact_email_primary", "custom_canvas_user_login_id"]'
          c.LTIExtraAuthenticator.user_id_regexes = json.loads(os.environ["LTI_ID_REGEXES"]) #eg '["(^[^@]+)@oregonstate.edu$", "(^[^@]+@[^@]+$)", "(^[0-9a-f]{6,6})[0-9a-f]*$"]'
          c.LTIExtraAuthenticator.user_admin_roles = json.loads(os.environ["LTI_ADMIN_ROLES"]) #eg '["Instructor", "TeachingAssistant", "ContentDeveloper"]'

        else:
          from jupyterhub.auth import DummyAuthenticator
          from tornado import gen

          class DummyExtraAuthenticator(DummyAuthenticator):
            @gen.coroutine
            def pre_spawn_start(self, user, spawner):
              spawner.environment['NB_USER'] = user.name
              spawner.environment['ADMIN_USER'] = str(user.admin)
       
          ## read admin user list from provided values 
          c.JupyterHub.authenticator_class = DummyExtraAuthenticator

        # don't use the ADMIN_USERS list if using lti auth - admin info is picked up in container
        if env_auth_type != "lti": 
          admin_users_comma_sep = os.environ["ADMIN_USERS"]  # grab admin usernames from environment variable set in questions.yaml
          admin_users = set([entry.strip() for entry in admin_users_comma_sep.split(",")]) # split it into a set to use
          c.Authenticator.admin_users = admin_users

        # allow admins to access user servers via UI (needs fixing, may not work with LTI?)
        c.JupyterHub.admin_access = True

